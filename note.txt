import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

# Load the dataset and extract faces (similar to previous code)
def load_faces(dataset_dir):
    # Load and preprocess images, detect faces, etc.
    ...

# Preprocess faces, split the dataset, encode labels, etc.
faces, labels = load_faces(dataset_dir)
...

# Create and train the face recognizer
face_recognizer = cv2.face.LBPHFaceRecognizer_create()
face_recognizer.train(faces, labels)

# Evaluate the model (for demonstration purposes)
predictions = []
for face in X_test:
    label, _ = face_recognizer.predict(face)
    predictions.append(label)

# Calculate accuracy
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)





import cv2
import os
import numpy as np
from sklearn.model_selection import train_test_split

# Function to load the dataset
def load_dataset(dataset_path):
    faces = []
    labels = []
    label_dict = {}
    current_label = 0

    for root, dirs, files in os.walk(dataset_path):
        for filename in files:
            if filename.endswith(('.png', '.jpg', '.jpeg')):
                label = os.path.basename(root)
                if label not in label_dict:
                    label_dict[label] = current_label
                    current_label += 1
                img_path = os.path.join(root, filename)
                image = cv2.imread(img_path)
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                faces.append(gray)
                labels.append(label_dict[label])

    return faces, np.array(labels)

# Function to train the recognizer
def train_recognizer(dataset_path):
    faces, labels = load_dataset(dataset_path)

    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(faces, labels, test_size=0.2, random_state=42)

    # Choose the recognizer algorithm (e.g., LBPH)
    recognizer = cv2.face.LBPHFaceRecognizer_create()

    # Train the recognizer on the training set
    recognizer.train(X_train, y_train)
    
    # Evaluate the recognizer on the testing set
    total = 0
    correct = 0
    for i in range(len(X_test)):
        label_predicted, _ = recognizer.predict(X_test[i])
        if label_predicted == y_test[i]:
            correct += 1
        total += 1

    accuracy = (correct / total) * 100
    print(f"Accuracy: {accuracy:.2f}%")

    recognizer.save("trained_model.yml")

    print("Training complete.")

if __name__ == "__main__":
    dataset_path = "./Humans"
    train_recognizer(dataset_path)














































import cv2
import matplotlib.pyplot as plt
import face_recognition

# Function to detect faces using webcam
face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

def detect_faces_image(image_path, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)):
    img = cv2.imread(image_path)
    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    faces = face_classifier.detectMultiScale(gray_image, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=minSize)
    
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)
    
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(20,10))
    plt.imshow(img_rgb)
    plt.axis('off')
    plt.show()

def detect_faces_video(video_path, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)):
    video_capture = cv2.VideoCapture(video_path)

    while True:
        result, video_frame = video_capture.read()
        if not result:
            break

        gray_image = cv2.cvtColor(video_frame, cv2.COLOR_BGR2GRAY)
        faces = face_classifier.detectMultiScale(gray_image, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=minSize)

        for (x, y, w, h) in faces:
            cv2.rectangle(video_frame, (x, y), (x + w, y + h), (0, 255, 0), 4)

        cv2.imshow("My Face Detection Project", video_frame)

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    video_capture.release()
    cv2.destroyAllWindows()

# Function to detect faces using webcam
def detect_faces_webcam(scaleFactor=1.1, minNeighbors=5, minSize=(40, 40), model_path=None):
    video_capture = cv2.VideoCapture(0)  # Use webcam (change the index if needed)
    recognizer = None

    # Load the trained recognizer
    if model_path:
        recognizer = load_recognizer(model_path)
        # Load the label dictionary used during training
        label_dict = load_label_dict()

    while True:
        result, video_frame = video_capture.read()
        if not result:
            break

        gray_image = cv2.cvtColor(video_frame, cv2.COLOR_BGR2GRAY)
        faces = face_classifier.detectMultiScale(gray_image, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=minSize)

        for (x, y, w, h) in faces:
            cv2.rectangle(video_frame, (x, y), (x + w, y + h), (0, 255, 0), 4)

            if recognizer:
                recognize_faces(video_frame, (x, y, w, h), recognizer, label_dict)

        cv2.imshow("My Face Detection Project", video_frame)

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    video_capture.release()
    cv2.destroyAllWindows()

# Function to load the trained recognizer
def load_recognizer(model_path):
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.read(model_path)
    return recognizer


# Function to detect faces using the trained recognizer
def recognize_faces(image, face_coords, recognizer, label_dict):
    (x, y, w, h) = face_coords
    roi_gray = cv2.cvtColor(image[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY)
    label_predicted, _ = recognizer.predict(roi_gray)
    
    # Get the name corresponding to the predicted label
    person_name = list(label_dict.keys())[list(label_dict.values()).index(label_predicted)]
    
    # Draw the predicted label on the image
    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 4)
    cv2.putText(image, person_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    return person_name


# Function to load the label dictionary used during training
def load_label_dict():
    label_dict = {}
    with open("label_dict.txt", "r") as file:
        for line in file:
            key, value = line.strip().split(",")
            label_dict[int(key)] = value
    return label_dict





def main(input_path, model_path, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)):
    if input_path.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):
        recognizer = load_recognizer(model_path)
    elif input_path.lower().endswith(('.mp4', '.avi', '.mov')):
        recognizer = load_recognizer(model_path)
    elif input_path.lower() == 'webcam':
        recognizer = load_recognizer(model_path)
        detect_faces_webcam(scaleFactor, minNeighbors, minSize)
    else:
        print("Unsupported input")

if __name__ == "__main__":
    input_path = "webcam"  # Change this to the path of your image, video file, or "webcam"
    model_path = "./trained_model.yml"  # Change this to the path of your trained model
    main(input_path, model_path, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))

